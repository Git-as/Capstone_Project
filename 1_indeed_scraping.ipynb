{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Indeed.com Scraping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Step 1: Figure out how to scrape the company data from Indeed.\n",
    "\n",
    "<font color='17321F'>\n",
    "    \n",
    "The data I want to scrape:\n",
    "\n",
    "* Reviews - Overall company Rating\n",
    "* Reviews - Work Life Balance Rating\n",
    "* Reviews - Pay and Benefits Rating\n",
    "* Reviews - Job Security and Advancement Rating\n",
    "* Reviews - Management Rating\n",
    "* Reviews - Culture Rating\n",
    "* Reviews - Overall company Rating\n",
    "* Reviews - count 5 star Rating\n",
    "* Reviews - count 4 star Rating\n",
    "* Reviews - count 3 star Rating\n",
    "* Reviews - count 2 star Rating\n",
    "* Reviews - count 1 star Rating\n",
    "* Reviews/UK - Reviews for UK (perform NLP):\n",
    "* number_of_reviews to know how many pages to loop through\n",
    "* review_date: can use this to choose which reviews I want to include in my dataset (convert to date and filter on dates not in the 'future')\n",
    "* review_header: one liner, review summary - NLP\n",
    "* review_text: main body of text - nlp\n",
    "* review_pros: pro's in note form - nlp\n",
    "* review_cons: con's in note form - nlp\n",
    "    \n",
    "Dropped Columns:\n",
    "* Snapshot - CEO\n",
    "* Snapshot - Founded (not sure how accurate this is, IQVIA says 2017?)\n",
    "* Snapshot - Company Size (This is categorical but worth comparing to the figure in the csv gender pay gap file)\n",
    "* Snapshot - Revenue (Gives an idea of how big the company is)\n",
    "* Snapshot - Industry (want to see if this impacts the overall statistics)\n",
    "* Snapshot - (!)About section (perform NLP on this) DECIDED TO DROP THIS BECAUSE NOT SURE HOW USEFUL IT WOULD BE\n",
    "    \n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time, random\n",
    "import math\n",
    "import re\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: load the data (trialled with 18_19 will do the other years later) and clean. Then created a dataframe with the first word of the company name column. Then scraped information from Indeed based using company = first word of the company name. This reduced the dataframe by about 20%, partially because some companies did not have a page on the site and also because the URL was incorrect for some of the company names using this method so it returned NA values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPG_18_19 = pd.read_csv('/Users/gitas/Desktop/GA/Capstone/Gender_Pay_Gap_Data/UK_Gender_Pay_Gap_Data_2018_2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPG_18_19.dropna(subset=['CompanyNumber', 'DiffMeanBonusPercent', 'DiffMedianBonusPercent'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPG_18_19.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8105 entries, 0 to 8104\n",
      "Data columns (total 25 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   EmployerName               8105 non-null   object \n",
      " 1   Address                    8105 non-null   object \n",
      " 2   CompanyNumber              8105 non-null   object \n",
      " 3   SicCodes                   7713 non-null   object \n",
      " 4   DiffMeanHourlyPercent      8105 non-null   float64\n",
      " 5   DiffMedianHourlyPercent    8105 non-null   float64\n",
      " 6   DiffMeanBonusPercent       8105 non-null   float64\n",
      " 7   DiffMedianBonusPercent     8105 non-null   float64\n",
      " 8   MaleBonusPercent           8105 non-null   float64\n",
      " 9   FemaleBonusPercent         8105 non-null   float64\n",
      " 10  MaleLowerQuartile          8105 non-null   float64\n",
      " 11  FemaleLowerQuartile        8105 non-null   float64\n",
      " 12  MaleLowerMiddleQuartile    8105 non-null   float64\n",
      " 13  FemaleLowerMiddleQuartile  8105 non-null   float64\n",
      " 14  MaleUpperMiddleQuartile    8105 non-null   float64\n",
      " 15  FemaleUpperMiddleQuartile  8105 non-null   float64\n",
      " 16  MaleTopQuartile            8105 non-null   float64\n",
      " 17  FemaleTopQuartile          8105 non-null   float64\n",
      " 18  CompanyLinkToGPGInfo       5669 non-null   object \n",
      " 19  ResponsiblePerson          7840 non-null   object \n",
      " 20  EmployerSize               8105 non-null   object \n",
      " 21  CurrentName                8105 non-null   object \n",
      " 22  SubmittedAfterTheDeadline  8105 non-null   bool   \n",
      " 23  DueDate                    8105 non-null   object \n",
      " 24  DateSubmitted              8105 non-null   object \n",
      "dtypes: bool(1), float64(14), object(10)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "GPG_18_19.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EmployerName</th>\n",
       "      <th>CompanyNumber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"RED BAND\" CHEMICAL COMPANY, LIMITED</td>\n",
       "      <td>SC016876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>118 LIMITED</td>\n",
       "      <td>03951948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>123 EMPLOYEES LTD</td>\n",
       "      <td>10530651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1509 GROUP</td>\n",
       "      <td>04104101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1610 LIMITED</td>\n",
       "      <td>06727055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           EmployerName CompanyNumber\n",
       "0  \"RED BAND\" CHEMICAL COMPANY, LIMITED      SC016876\n",
       "1                           118 LIMITED      03951948\n",
       "2                     123 EMPLOYEES LTD      10530651\n",
       "3                            1509 GROUP      04104101\n",
       "4                          1610 LIMITED      06727055"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indeed_companies = GPG_18_19[['EmployerName', 'CompanyNumber']]\n",
    "indeed_companies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "employer_clean = []\n",
    "for line in indeed_companies.EmployerName:\n",
    "    employer_clean.append((line.split(' ', 1)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-f7dfa015b717>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  indeed_companies['employer_clean'] = employer_clean\n"
     ]
    }
   ],
   "source": [
    "indeed_companies['employer_clean'] = employer_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indeed_comp.to_csv('indeed_companies', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "indeed_comp = pd.read_csv('indeed_companies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EmployerName</th>\n",
       "      <th>CompanyNumber</th>\n",
       "      <th>employer_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"RED BAND\" CHEMICAL COMPANY, LIMITED</td>\n",
       "      <td>SC016876</td>\n",
       "      <td>\"RED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>118 LIMITED</td>\n",
       "      <td>03951948</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>123 EMPLOYEES LTD</td>\n",
       "      <td>10530651</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1509 GROUP</td>\n",
       "      <td>04104101</td>\n",
       "      <td>1509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1610 LIMITED</td>\n",
       "      <td>06727055</td>\n",
       "      <td>1610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           EmployerName CompanyNumber employer_clean\n",
       "0  \"RED BAND\" CHEMICAL COMPANY, LIMITED      SC016876           \"RED\n",
       "1                           118 LIMITED      03951948            118\n",
       "2                     123 EMPLOYEES LTD      10530651            123\n",
       "3                            1509 GROUP      04104101           1509\n",
       "4                          1610 LIMITED      06727055           1610"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indeed_comp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "\n",
    "#### Note - for all the below scrapes, I did these for a few companies at a time (around 500-1000), converted to a dataframe, saved to csv then ran for the next few companies. This was to ensure that if I got blocked from the site or had any issues with internet connection I would still have some of the data saved.\n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: First scrape was for the CEO, founded, company size, revenue and industry but these fields were later dropped because I noticed that not all company had all these fields completed so there would be a large number of NA's and I did not want to lose anymore rows. Also, a lot of this information I could get from companies house. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping the company stats:\n",
    "url_template = \"https://uk.indeed.com/cmp/{}\"\n",
    "CEO = []\n",
    "founded = []\n",
    "company_size = []\n",
    "revenue = []\n",
    "industry = []\n",
    "for company in indeed_comp.employer_clean[100:110]:\n",
    "    time.sleep(random.randint(1, 4))\n",
    "    r = requests.get(url_template.format(company))\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    try:\n",
    "        CEO.append(soup.find('li', attrs={'class':\"css-v4e08k eu4oa1w0\", 'data-testid':\"companyInfo-ceo\"}).text[3:].strip())\n",
    "    except:\n",
    "        CEO.append(np.nan)\n",
    "    try:\n",
    "        founded.append(soup.find('li', attrs={'class':\"css-v4e08k eu4oa1w0\", 'data-testid':\"companyInfo-founded\"}).text[7:].strip())\n",
    "    except:\n",
    "        founded.append(np.nan)\n",
    "    try:\n",
    "        company_size.append(soup.find('li', attrs={'class':\"css-v4e08k eu4oa1w0\", 'data-testid':\"companyInfo-employee\"}).text[12:].strip())\n",
    "    except:\n",
    "        company_size.append(np.nan)\n",
    "    try:\n",
    "        revenue.append(soup.find('li', attrs={'class':\"css-v4e08k eu4oa1w0\", 'data-testid':\"companyInfo-revenue\"}).text[7:].strip())\n",
    "    except:\n",
    "        revenue.append(np.nan)\n",
    "    try:\n",
    "        industry.append(soup.find('li', attrs={'class':\"css-v4e08k eu4oa1w0\", 'data-testid':\"companyInfo-industry\"}).text[8:].strip())\n",
    "    except:\n",
    "        industry.append(np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Scrape all the rating scores - overall and categorical and save to a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping the overall and category ratings:\n",
    "url_template = \"https://uk.indeed.com/cmp/{}/reviews\"\n",
    "company_no = []\n",
    "number_of_reviews = []\n",
    "company_rating = []\n",
    "\n",
    "work_life_balance = []\n",
    "pay_and_benefits = []\n",
    "job_security_and_advancement = []\n",
    "management = []\n",
    "culture = []\n",
    "\n",
    "for company in indeed_comp.employer_clean[100:110]:\n",
    "    time.sleep(random.randint(1, 4))\n",
    "    r = requests.get(url_template.format(company))\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    try:\n",
    "        number_of_reviews.append(soup.find('a', class_=\"cmp-RatingsCountLink\").text.strip())\n",
    "    except:\n",
    "        number_of_reviews.append(np.nan)\n",
    "    try:\n",
    "        company_rating.append(soup.find('span', class_=\"cmp-CompactHeaderCompanyRatings-value\").text.strip())\n",
    "    except:\n",
    "        company_rating.append(np.nan)\n",
    "    try:\n",
    "        work_life_balance.append(soup.find('div', class_=\"cmp-ReviewsFilters-singleSection\").text[19:22].strip())\n",
    "    except:\n",
    "        work_life_balance.append(np.nan)\n",
    "    try:\n",
    "        pay_and_benefits.append(soup.find('div', class_=\"cmp-ReviewsFilters-singleSection\").text[39:42].strip())\n",
    "    except:\n",
    "        pay_and_benefits.append(np.nan)\n",
    "    try:\n",
    "        job_security_and_advancement.append(soup.find('div', class_=\"cmp-ReviewsFilters-singleSection\").text[56:59].strip())\n",
    "    except:\n",
    "        job_security_and_advancement.append(np.nan)\n",
    "    try:\n",
    "        management.append(soup.find('div', class_=\"cmp-ReviewsFilters-singleSection\").text[85:88].strip())\n",
    "    except:\n",
    "        management.append(np.nan)\n",
    "    try:\n",
    "        culture.append(soup.find('div', class_=\"cmp-ReviewsFilters-singleSection\").text[98:101].strip())\n",
    "    except:\n",
    "        culture.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_ratings_100_110 = pd.DataFrame()\n",
    "\n",
    "category_ratings_100_110['number_of_reviews'] = number_of_reviews\n",
    "category_ratings_100_110['company_rating'] = company_rating\n",
    "category_ratings_100_110['work_life_balance'] = work_life_balance\n",
    "category_ratings_100_110['pay_and_benefits'] = pay_and_benefits\n",
    "category_ratings_100_110['job_security_and_advancement'] = job_security_and_advancement\n",
    "category_ratings_100_110['management'] = management\n",
    "category_ratings_100_110['culture'] = culture\n",
    "\n",
    "# category_ratings_0_2000.to_csv('category_ratings_0_2000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>company_rating</th>\n",
       "      <th>work_life_balance</th>\n",
       "      <th>pay_and_benefits</th>\n",
       "      <th>job_security_and_advancement</th>\n",
       "      <th>management</th>\n",
       "      <th>culture</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25 reviews</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1 review</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>107 reviews</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6 reviews</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15 reviews</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>216 reviews</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>43 reviews</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>43 reviews</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  number_of_reviews company_rating work_life_balance pay_and_benefits  \\\n",
       "0        25 reviews            3.2               3.1              3.0   \n",
       "1               NaN            NaN               NaN              NaN   \n",
       "2          1 review            5.0               5.0              5.0   \n",
       "3               NaN            NaN               NaN              NaN   \n",
       "4       107 reviews            3.7               3.8              3.6   \n",
       "5         6 reviews            3.5               3.0              3.8   \n",
       "6        15 reviews            3.4               3.5              3.5   \n",
       "7       216 reviews            3.4               3.3              3.1   \n",
       "8        43 reviews            3.4               3.1              2.9   \n",
       "9        43 reviews            3.4               3.1              2.9   \n",
       "\n",
       "  job_security_and_advancement management culture  \n",
       "0                          2.8        3.0     2.7  \n",
       "1                          NaN        NaN     NaN  \n",
       "2                          5.0        5.0     5.0  \n",
       "3                          NaN        NaN     NaN  \n",
       "4                          3.1        3.4     3.5  \n",
       "5                          3.0        3.2     3.2  \n",
       "6                          3.2        3.3     3.4  \n",
       "7                          2.9        3.1     3.3  \n",
       "8                          2.8        2.8     3.2  \n",
       "9                          2.8        2.8     3.2  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_ratings_100_110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# category_ratings_18_19 = pd.concat([category_ratings_18_19, indeed_comp], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Scrape the star rating counts and save to a dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping the 1-5 * ratings\n",
    "url_template = \"https://uk.indeed.com/cmp/{}/reviews\"\n",
    "count_5_star = []\n",
    "count_4_star = []\n",
    "count_3_star = []\n",
    "count_2_star = []\n",
    "count_1_star = []\n",
    "\n",
    "for company in indeed_comp.employer_clean[100:110]:\n",
    "    time.sleep(random.randint(1, 4))\n",
    "    r = requests.get(url_template.format(company))\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')  \n",
    "    try:\n",
    "        first_rating = soup.find('div', class_=\"cmp-ReviewHistogram-row\")\n",
    "        count_5_star.append(first_rating.text[1:].strip())\n",
    "    except:\n",
    "        count_5_star.append(np.nan)\n",
    "    \n",
    "    try:\n",
    "        second_rating = first_rating.find_next_sibling('div')\n",
    "        count_4_star.append(second_rating.text[1:].strip())\n",
    "    except:\n",
    "        count_4_star.append(np.nan)\n",
    "    \n",
    "    try:\n",
    "        third_rating = second_rating.find_next_sibling('div')\n",
    "        count_3_star.append(third_rating.text[1:].strip())\n",
    "    except:\n",
    "        count_3_star.append(np.nan)\n",
    "    \n",
    "    try:\n",
    "        forth_rating = third_rating.find_next_sibling('div')\n",
    "        count_2_star.append(forth_rating.text[1:].strip())\n",
    "    except:\n",
    "        count_2_star.append(np.nan)\n",
    "    \n",
    "    try:\n",
    "        fifth_rating = forth_rating.find_next_sibling('div')\n",
    "        count_1_star.append(fifth_rating.text[1:].strip())\n",
    "    except:\n",
    "        count_1_star.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_ratings_100_110 = pd.DataFrame()\n",
    "\n",
    "star_ratings_100_110['count_5_star'] = count_5_star\n",
    "star_ratings_100_110['count_4_star'] = count_4_star\n",
    "star_ratings_100_110['count_3_star'] = count_3_star\n",
    "star_ratings_100_110['count_2_star'] = count_2_star\n",
    "star_ratings_100_110['count_1_star'] = count_1_star\n",
    "\n",
    "# star_ratings_0_2000.to_csv('star_ratings_0_2000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count_5_star</th>\n",
       "      <th>count_4_star</th>\n",
       "      <th>count_3_star</th>\n",
       "      <th>count_2_star</th>\n",
       "      <th>count_1_star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>36</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>55</td>\n",
       "      <td>59</td>\n",
       "      <td>50</td>\n",
       "      <td>19</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  count_5_star count_4_star count_3_star count_2_star count_1_star\n",
       "0            7            4            6            2            6\n",
       "1          NaN          NaN            6            2            6\n",
       "2            1            0            0            0            0\n",
       "3          NaN          NaN            0            0            0\n",
       "4           33           36           22           10            6\n",
       "5            1            2            2            1            0\n",
       "6            3            6            2            2            2\n",
       "7           55           59           50           19           33\n",
       "8           14            8           10            2            9\n",
       "9           14            8           10            2            9"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "star_ratings_100_110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# star_ratings_18_19 = pd.concat([star_ratings_18_19, category_ratings_18_19], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# star_ratings_18_19.to_csv('all_ratings_18_19', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ratings_18_19 = pd.read_csv('all_ratings_18_19.csv')\n",
    "all_ratings_18_19.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Scrape the review data (pros, cons, main text and header). To do this, I had to do two things, before saving to a dataframe:\n",
    " ### a) Identify the number of pages to loop through for each company - there was a number at the top stating the total number of reviews and I knew each page displays 20 results and I didn't want any repeats as it would have been quite difficult to get rid of duplicates, since all reviews would be included in the same row of the dataframe as one list. I wrote a formula that used the total number of reviews to determine how many pages to loop through.\n",
    "### b) Scrape the date of review, convert to a datetime series and ensure that the date of the review is not after gender pay gap data period. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping the review data: after applying the datetime filter\n",
    "url_template = \"https://uk.indeed.com/cmp/{}/reviews?fcountry=GB&start={}\"\n",
    "review_date = []\n",
    "review_header = []\n",
    "review_text = []\n",
    "review_pros = []\n",
    "review_cons = []\n",
    "march_31_2019 = datetime(2019, 3, 31).toordinal()\n",
    "\n",
    "for company in indeed_comp.employer_clean[100:110]:\n",
    "    company_date = []\n",
    "    company_header = []\n",
    "    company_text = []\n",
    "    company_pros = []\n",
    "    company_cons = []\n",
    "\n",
    "    url_template_company = \"https://uk.indeed.com/cmp/{}/reviews?fcountry=GB\"\n",
    "    r_company = requests.get(url_template_company.format(company))\n",
    "    soup_company = BeautifulSoup(r_company.text, 'html.parser')\n",
    "    counts = soup_company.find('div', attrs={'class':\"cmp-ReviewsCount\"})\n",
    "    try:\n",
    "        number_reviews = int((counts.findChild('b').text.strip()))\n",
    "    except:\n",
    "        number_reviews = 20\n",
    "    max_reviews = ((math.ceil(number_reviews/20)))*20\n",
    "    for page in range(0,max_reviews,20):\n",
    "        time.sleep(random.randint(1, 4))\n",
    "        r = requests.get(url_template.format(company, page))\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "        for review in soup.find_all('div', attrs={'class':\"cmp-Review\", 'itemprop':'review'}):\n",
    "            try:\n",
    "                review_author = review.find('span', attrs={'class':\"cmp-ReviewAuthor\"}).text.strip()\n",
    "                date = re.findall(r'(\\w+\\s\\w+\\s\\w+)$', review_author)\n",
    "                for i in date:\n",
    "                    datetime_object = datetime.strptime(i, '%d %B %Y')\n",
    "                \n",
    "                if datetime_object.toordinal() < march_31_2019:\n",
    "                    company_date.append(date)\n",
    "                else:\n",
    "                    pass\n",
    "                \n",
    "            except:\n",
    "                pass\n",
    "                \n",
    "            if datetime_object.toordinal() < march_31_2019:\n",
    "                try:\n",
    "                    company_header.append(review.find('a', attrs={'class':\"cmp-Review-titleLink\"}).text.strip())\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                text_section = review.find('div', attrs={'class':\"cmp-Review-text\"})\n",
    "                try:\n",
    "                    company_text.append(text_section.findChild('span', attrs={'class':\"cmp-NewLineToBr-text\"}).text.strip())\n",
    "                except:\n",
    "                    pass\n",
    "                pros_section = review.find('div', attrs={'class':\"cmp-ReviewProsCons-prosText\"})\n",
    "                try: \n",
    "                    company_pros.append(pros_section.find('span', attrs={'class':\"cmp-NewLineToBr-text\"}).text.strip())\n",
    "                except:\n",
    "                    pass\n",
    "                cons_section = review.find('div', attrs={'class':\"cmp-ReviewProsCons-consText\"})\n",
    "                try: \n",
    "                    company_cons.append(cons_section.find('span', attrs={'class':\"cmp-NewLineToBr-text\"}).text.strip())\n",
    "                except:\n",
    "                    pass\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    review_date.append(company_date)\n",
    "    review_header.append(company_header)\n",
    "    review_text.append(company_text)\n",
    "    review_pros.append(company_pros)\n",
    "    review_cons.append(company_cons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_details_100_110 = pd.DataFrame()\n",
    "\n",
    "review_details_100_110['review_date'] = review_date\n",
    "review_details_100_110['review_header'] = review_header\n",
    "review_details_100_110['review_text'] = review_text\n",
    "review_details_100_110['review_pros'] = review_pros\n",
    "review_details_100_110['review_cons'] = review_cons\n",
    "\n",
    "# review_details_0_500.to_csv('review_details_0_500')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_header</th>\n",
       "      <th>review_text</th>\n",
       "      <th>review_pros</th>\n",
       "      <th>review_cons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[9 August 2017], [6 June 2018], [4 March 2018...</td>\n",
       "      <td>[Friendly, fun place to work, fun and professi...</td>\n",
       "      <td>[I enjoyed working there., This was a very goo...</td>\n",
       "      <td>[Friendly, easy hours, free lunch, being left ...</td>\n",
       "      <td>[Split shifts, physically exhausting, notg eno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[1 February 2013], [5 January 2018], [14 Augu...</td>\n",
       "      <td>[An intresting challenge., do not trust this c...</td>\n",
       "      <td>[A typical day at work involves dealing with i...</td>\n",
       "      <td>[exciting time, met a lot of users, Warning, F...</td>\n",
       "      <td>[long but intresting, Warning, Pay, short pays...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[[6 September 2017], [11 December 2015], [19 F...</td>\n",
       "      <td>[Fun and creative job, Enjoyable but very trav...</td>\n",
       "      <td>[It's a fun a creative place to do what you lo...</td>\n",
       "      <td>[Get your hair done for free, Exposed to main ...</td>\n",
       "      <td>[Can be Long hours, Long hours and lots of tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[[14 January 2018], [13 November 2018], [8 Feb...</td>\n",
       "      <td>[Fun workplace, Its a job, Worse place ever, I...</td>\n",
       "      <td>[Good Working Environment with international a...</td>\n",
       "      <td>[wages]</td>\n",
       "      <td>[traveling, Long hours, poor working condition...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[[29 May 2018], [19 November 2018], [2 July 20...</td>\n",
       "      <td>[Great Sense of Community, Boring, Very fun an...</td>\n",
       "      <td>[In regards to its property management departm...</td>\n",
       "      <td>[Teamwork, Money, Beach, Colleagues and workpl...</td>\n",
       "      <td>[Workload, Less, Pay is embrassingly low. The ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[[29 May 2018], [19 November 2018], [2 July 20...</td>\n",
       "      <td>[Great Sense of Community, Boring, Very fun an...</td>\n",
       "      <td>[In regards to its property management departm...</td>\n",
       "      <td>[Teamwork, Money, Beach, Colleagues and workpl...</td>\n",
       "      <td>[Workload, Less, Pay is embrassingly low. The ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_date  \\\n",
       "0  [[9 August 2017], [6 June 2018], [4 March 2018...   \n",
       "1                                                 []   \n",
       "2                                                 []   \n",
       "3                                                 []   \n",
       "4  [[1 February 2013], [5 January 2018], [14 Augu...   \n",
       "5                                                 []   \n",
       "6  [[6 September 2017], [11 December 2015], [19 F...   \n",
       "7  [[14 January 2018], [13 November 2018], [8 Feb...   \n",
       "8  [[29 May 2018], [19 November 2018], [2 July 20...   \n",
       "9  [[29 May 2018], [19 November 2018], [2 July 20...   \n",
       "\n",
       "                                       review_header  \\\n",
       "0  [Friendly, fun place to work, fun and professi...   \n",
       "1                                                 []   \n",
       "2                                                 []   \n",
       "3                                                 []   \n",
       "4  [An intresting challenge., do not trust this c...   \n",
       "5                                                 []   \n",
       "6  [Fun and creative job, Enjoyable but very trav...   \n",
       "7  [Fun workplace, Its a job, Worse place ever, I...   \n",
       "8  [Great Sense of Community, Boring, Very fun an...   \n",
       "9  [Great Sense of Community, Boring, Very fun an...   \n",
       "\n",
       "                                         review_text  \\\n",
       "0  [I enjoyed working there., This was a very goo...   \n",
       "1                                                 []   \n",
       "2                                                 []   \n",
       "3                                                 []   \n",
       "4  [A typical day at work involves dealing with i...   \n",
       "5                                                 []   \n",
       "6  [It's a fun a creative place to do what you lo...   \n",
       "7  [Good Working Environment with international a...   \n",
       "8  [In regards to its property management departm...   \n",
       "9  [In regards to its property management departm...   \n",
       "\n",
       "                                         review_pros  \\\n",
       "0  [Friendly, easy hours, free lunch, being left ...   \n",
       "1                                                 []   \n",
       "2                                                 []   \n",
       "3                                                 []   \n",
       "4  [exciting time, met a lot of users, Warning, F...   \n",
       "5                                                 []   \n",
       "6  [Get your hair done for free, Exposed to main ...   \n",
       "7                                            [wages]   \n",
       "8  [Teamwork, Money, Beach, Colleagues and workpl...   \n",
       "9  [Teamwork, Money, Beach, Colleagues and workpl...   \n",
       "\n",
       "                                         review_cons  \n",
       "0  [Split shifts, physically exhausting, notg eno...  \n",
       "1                                                 []  \n",
       "2                                                 []  \n",
       "3                                                 []  \n",
       "4  [long but intresting, Warning, Pay, short pays...  \n",
       "5                                                 []  \n",
       "6  [Can be Long hours, Long hours and lots of tra...  \n",
       "7  [traveling, Long hours, poor working condition...  \n",
       "8  [Workload, Less, Pay is embrassingly low. The ...  \n",
       "9  [Workload, Less, Pay is embrassingly low. The ...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_details_100_110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_reviews_18_19 = pd.concat([review_details_18_19, all_ratings_18_19], axis=1)\n",
    "# all_reviews_18_19.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_reviews_18_19.to_csv('all_reviews_18_19', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

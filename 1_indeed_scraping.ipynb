{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Indeed.com Scraping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Step 1: Figure out how to scrape the company data from Indeed.\n",
    "\n",
    "<font color='17321F'>\n",
    "    \n",
    "The data I want to scrape:\n",
    "\n",
    "* Reviews - Overall company Rating\n",
    "* Reviews - Work Life Balance Rating\n",
    "* Reviews - Pay and Benefits Rating\n",
    "* Reviews - Job Security and Advancement Rating\n",
    "* Reviews - Management Rating\n",
    "* Reviews - Culture Rating\n",
    "* Reviews - Overall company Rating\n",
    "* Reviews - count 5 star Rating\n",
    "* Reviews - count 4 star Rating\n",
    "* Reviews - count 3 star Rating\n",
    "* Reviews - count 2 star Rating\n",
    "* Reviews - count 1 star Rating\n",
    "* Reviews/UK - Reviews for UK (perform NLP):\n",
    "* number_of_reviews to know how many pages to loop through\n",
    "* review_date: can use this to choose which reviews I want to include in my dataset (convert to date and filter on dates not in the 'future')\n",
    "* review_header: one liner, review summary - NLP\n",
    "* review_text: main body of text - nlp\n",
    "* review_pros: pro's in note form - nlp\n",
    "* review_cons: con's in note form - nlp\n",
    "    \n",
    "Dropped Columns:\n",
    "* Snapshot - CEO\n",
    "* Snapshot - Founded (not sure how accurate this is, IQVIA says 2017?)\n",
    "* Snapshot - Company Size (This is categorical but worth comparing to the figure in the csv gender pay gap file)\n",
    "* Snapshot - Revenue (Gives an idea of how big the company is)\n",
    "* Snapshot - Industry (want to see if this impacts the overall statistics)\n",
    "* Snapshot - (!)About section (perform NLP on this) DECIDED TO DROP THIS BECAUSE NOT SURE HOW USEFUL IT WOULD BE\n",
    "    \n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time, random\n",
    "import math\n",
    "import re\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: load the data (trialled with 18_19 will do the other years later) and clean. Then created a dataframe with the first word of the company name column. Then scraped information from Indeed based using company = first word of the company name. This reduced the dataframe by about 20%, partially because some companies did not have a page on the site and also because the URL was incorrect for some of the company names using this method so it returned NA values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPG_18_19 = pd.read_csv('/Users/gitas/Desktop/GA/Capstone/Gender_Pay_Gap_Data/UK_Gender_Pay_Gap_Data_2018_2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPG_18_19.dropna(subset=['CompanyNumber', 'DiffMeanBonusPercent', 'DiffMedianBonusPercent'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPG_18_19.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8105 entries, 0 to 8104\n",
      "Data columns (total 25 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   EmployerName               8105 non-null   object \n",
      " 1   Address                    8105 non-null   object \n",
      " 2   CompanyNumber              8105 non-null   object \n",
      " 3   SicCodes                   7713 non-null   object \n",
      " 4   DiffMeanHourlyPercent      8105 non-null   float64\n",
      " 5   DiffMedianHourlyPercent    8105 non-null   float64\n",
      " 6   DiffMeanBonusPercent       8105 non-null   float64\n",
      " 7   DiffMedianBonusPercent     8105 non-null   float64\n",
      " 8   MaleBonusPercent           8105 non-null   float64\n",
      " 9   FemaleBonusPercent         8105 non-null   float64\n",
      " 10  MaleLowerQuartile          8105 non-null   float64\n",
      " 11  FemaleLowerQuartile        8105 non-null   float64\n",
      " 12  MaleLowerMiddleQuartile    8105 non-null   float64\n",
      " 13  FemaleLowerMiddleQuartile  8105 non-null   float64\n",
      " 14  MaleUpperMiddleQuartile    8105 non-null   float64\n",
      " 15  FemaleUpperMiddleQuartile  8105 non-null   float64\n",
      " 16  MaleTopQuartile            8105 non-null   float64\n",
      " 17  FemaleTopQuartile          8105 non-null   float64\n",
      " 18  CompanyLinkToGPGInfo       5669 non-null   object \n",
      " 19  ResponsiblePerson          7840 non-null   object \n",
      " 20  EmployerSize               8105 non-null   object \n",
      " 21  CurrentName                8105 non-null   object \n",
      " 22  SubmittedAfterTheDeadline  8105 non-null   bool   \n",
      " 23  DueDate                    8105 non-null   object \n",
      " 24  DateSubmitted              8105 non-null   object \n",
      "dtypes: bool(1), float64(14), object(10)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "GPG_18_19.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EmployerName</th>\n",
       "      <th>CompanyNumber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"RED BAND\" CHEMICAL COMPANY, LIMITED</td>\n",
       "      <td>SC016876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>118 LIMITED</td>\n",
       "      <td>03951948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>123 EMPLOYEES LTD</td>\n",
       "      <td>10530651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1509 GROUP</td>\n",
       "      <td>04104101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1610 LIMITED</td>\n",
       "      <td>06727055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           EmployerName CompanyNumber\n",
       "0  \"RED BAND\" CHEMICAL COMPANY, LIMITED      SC016876\n",
       "1                           118 LIMITED      03951948\n",
       "2                     123 EMPLOYEES LTD      10530651\n",
       "3                            1509 GROUP      04104101\n",
       "4                          1610 LIMITED      06727055"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indeed_companies = GPG_18_19[['EmployerName', 'CompanyNumber']]\n",
    "indeed_companies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "employer_clean = []\n",
    "for line in indeed_companies.EmployerName:\n",
    "    employer_clean.append((line.split(' ', 1)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-f7dfa015b717>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  indeed_companies['employer_clean'] = employer_clean\n"
     ]
    }
   ],
   "source": [
    "indeed_companies['employer_clean'] = employer_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indeed_comp.to_csv('indeed_companies', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "indeed_comp = pd.read_csv('indeed_companies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EmployerName</th>\n",
       "      <th>CompanyNumber</th>\n",
       "      <th>employer_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"RED BAND\" CHEMICAL COMPANY, LIMITED</td>\n",
       "      <td>SC016876</td>\n",
       "      <td>\"RED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>118 LIMITED</td>\n",
       "      <td>03951948</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>123 EMPLOYEES LTD</td>\n",
       "      <td>10530651</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1509 GROUP</td>\n",
       "      <td>04104101</td>\n",
       "      <td>1509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1610 LIMITED</td>\n",
       "      <td>06727055</td>\n",
       "      <td>1610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           EmployerName CompanyNumber employer_clean\n",
       "0  \"RED BAND\" CHEMICAL COMPANY, LIMITED      SC016876           \"RED\n",
       "1                           118 LIMITED      03951948            118\n",
       "2                     123 EMPLOYEES LTD      10530651            123\n",
       "3                            1509 GROUP      04104101           1509\n",
       "4                          1610 LIMITED      06727055           1610"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indeed_comp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "\n",
    "#### Note - for all the below scrapes, I did these for a few companies at a time (around 500-1000), converted to a dataframe, saved to csv then ran for the next few companies. This was to ensure that if I got blocked from the site or had any issues with internet connection I would still have some of the data saved.\n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: First scrape was for the CEO, founded, company size, revenue and industry but these fields were later dropped because I noticed that not all company had all these fields completed so there would be a large number of NA's and I did not want to lose anymore rows. Also, a lot of this information I could get from companies house. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping the company stats:\n",
    "url_template = \"https://uk.indeed.com/cmp/{}\"\n",
    "CEO = []\n",
    "founded = []\n",
    "company_size = []\n",
    "revenue = []\n",
    "industry = []\n",
    "for company in indeed_comp.employer_clean[0:2000]:\n",
    "    time.sleep(random.randint(1, 4))\n",
    "    r = requests.get(url_template.format(company))\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    try:\n",
    "        CEO.append(soup.find('li', attrs={'class':\"css-v4e08k eu4oa1w0\", 'data-testid':\"companyInfo-ceo\"}).text[3:].strip())\n",
    "    except:\n",
    "        CEO.append(np.nan)\n",
    "    try:\n",
    "        founded.append(soup.find('li', attrs={'class':\"css-v4e08k eu4oa1w0\", 'data-testid':\"companyInfo-founded\"}).text[7:].strip())\n",
    "    except:\n",
    "        founded.append(np.nan)\n",
    "    try:\n",
    "        company_size.append(soup.find('li', attrs={'class':\"css-v4e08k eu4oa1w0\", 'data-testid':\"companyInfo-employee\"}).text[12:].strip())\n",
    "    except:\n",
    "        company_size.append(np.nan)\n",
    "    try:\n",
    "        revenue.append(soup.find('li', attrs={'class':\"css-v4e08k eu4oa1w0\", 'data-testid':\"companyInfo-revenue\"}).text[7:].strip())\n",
    "    except:\n",
    "        revenue.append(np.nan)\n",
    "    try:\n",
    "        industry.append(soup.find('li', attrs={'class':\"css-v4e08k eu4oa1w0\", 'data-testid':\"companyInfo-industry\"}).text[8:].strip())\n",
    "    except:\n",
    "        industry.append(np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Scrape all the rating scores - overall and categorical and save to a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping the overall and category ratings:\n",
    "url_template = \"https://uk.indeed.com/cmp/{}/reviews\"\n",
    "company_no = []\n",
    "number_of_reviews = []\n",
    "company_rating = []\n",
    "\n",
    "work_life_balance = []\n",
    "pay_and_benefits = []\n",
    "job_security_and_advancement = []\n",
    "management = []\n",
    "culture = []\n",
    "\n",
    "for company in indeed_comp.employer_clean[0:2000]:\n",
    "    time.sleep(random.randint(1, 4))\n",
    "    r = requests.get(url_template.format(company))\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    company_no\n",
    "    try:\n",
    "        number_of_reviews.append(soup.find('a', class_=\"cmp-RatingsCountLink\").text.strip())\n",
    "    except:\n",
    "        number_of_reviews.append(np.nan)\n",
    "    try:\n",
    "        company_rating.append(soup.find('span', class_=\"cmp-CompactHeaderCompanyRatings-value\").text.strip())\n",
    "    except:\n",
    "        company_rating.append(np.nan)\n",
    "    try:\n",
    "        work_life_balance.append(soup.find('div', class_=\"cmp-ReviewsFilters-singleSection\").text[19:22].strip())\n",
    "    except:\n",
    "        work_life_balance.append(np.nan)\n",
    "    try:\n",
    "        pay_and_benefits.append(soup.find('div', class_=\"cmp-ReviewsFilters-singleSection\").text[39:42].strip())\n",
    "    except:\n",
    "        pay_and_benefits.append(np.nan)\n",
    "    try:\n",
    "        job_security_and_advancement.append(soup.find('div', class_=\"cmp-ReviewsFilters-singleSection\").text[56:59].strip())\n",
    "    except:\n",
    "        job_security_and_advancement.append(np.nan)\n",
    "    try:\n",
    "        management.append(soup.find('div', class_=\"cmp-ReviewsFilters-singleSection\").text[85:88].strip())\n",
    "    except:\n",
    "        management.append(np.nan)\n",
    "    try:\n",
    "        culture.append(soup.find('div', class_=\"cmp-ReviewsFilters-singleSection\").text[98:101].strip())\n",
    "    except:\n",
    "        culture.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# category_ratings_0_2000 = pd.DataFrame()\n",
    "\n",
    "# category_ratings_0_2000['number_of_reviews'] = number_of_reviews\n",
    "# category_ratings_0_2000['company_rating'] = company_rating\n",
    "# category_ratings_0_2000['work_life_balance'] = work_life_balance\n",
    "# category_ratings_0_2000['pay_and_benefits'] = pay_and_benefits\n",
    "# category_ratings_0_2000['job_security_and_advancement'] = job_security_and_advancement\n",
    "# category_ratings_0_2000['management'] = management\n",
    "# category_ratings_0_2000['culture'] = culture\n",
    "\n",
    "# category_ratings_0_2000.to_csv('category_ratings_0_2000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# category_ratings_18_19 = pd.concat([category_ratings_18_19, indeed_comp], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_ratings_18_19 = pd.read_csv('category_ratings_18_19')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8105 entries, 0 to 8104\n",
      "Data columns (total 10 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   number_of_reviews             6593 non-null   object \n",
      " 1   company_rating                6593 non-null   float64\n",
      " 2   work_life_balance             6591 non-null   object \n",
      " 3   pay_and_benefits              6591 non-null   object \n",
      " 4   job_security_and_advancement  6591 non-null   object \n",
      " 5   management                    6591 non-null   object \n",
      " 6   culture                       6560 non-null   object \n",
      " 7   EmployerName                  8105 non-null   object \n",
      " 8   CompanyNumber                 8105 non-null   object \n",
      " 9   employer_clean                8105 non-null   object \n",
      "dtypes: float64(1), object(9)\n",
      "memory usage: 633.3+ KB\n"
     ]
    }
   ],
   "source": [
    "category_ratings_18_19.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Scrape the star rating counts and save to a dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping the 1-5 * ratings\n",
    "url_template = \"https://uk.indeed.com/cmp/{}/reviews\"\n",
    "count_5_star = []\n",
    "count_4_star = []\n",
    "count_3_star = []\n",
    "count_2_star = []\n",
    "count_1_star = []\n",
    "\n",
    "for company in indeed_comp.employer_clean[6105:8105]:\n",
    "    time.sleep(random.randint(1, 4))\n",
    "    r = requests.get(url_template.format(company))\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')  \n",
    "    try:\n",
    "        first_rating = soup.find('div', class_=\"cmp-ReviewHistogram-row\")\n",
    "        count_5_star.append(first_rating.text[1:].strip())\n",
    "    except:\n",
    "        count_5_star.append(np.nan)\n",
    "    \n",
    "    try:\n",
    "        second_rating = first_rating.find_next_sibling('div')\n",
    "        count_4_star.append(second_rating.text[1:].strip())\n",
    "    except:\n",
    "        count_4_star.append(np.nan)\n",
    "    \n",
    "    try:\n",
    "        third_rating = second_rating.find_next_sibling('div')\n",
    "        count_3_star.append(third_rating.text[1:].strip())\n",
    "    except:\n",
    "        count_3_star.append(np.nan)\n",
    "    \n",
    "    try:\n",
    "        forth_rating = third_rating.find_next_sibling('div')\n",
    "        count_2_star.append(forth_rating.text[1:].strip())\n",
    "    except:\n",
    "        count_2_star.append(np.nan)\n",
    "    \n",
    "    try:\n",
    "        fifth_rating = forth_rating.find_next_sibling('div')\n",
    "        count_1_star.append(fifth_rating.text[1:].strip())\n",
    "    except:\n",
    "        count_1_star.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   count_5_star  1464 non-null   object\n",
      " 1   count_4_star  1464 non-null   object\n",
      " 2   count_3_star  2000 non-null   object\n",
      " 3   count_2_star  2000 non-null   object\n",
      " 4   count_1_star  2000 non-null   object\n",
      "dtypes: object(5)\n",
      "memory usage: 78.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# star_ratings_0_2000 = pd.DataFrame()\n",
    "\n",
    "# star_ratings_0_2000['count_5_star'] = count_5_star\n",
    "# star_ratings_0_2000['count_4_star'] = count_4_star\n",
    "# star_ratings_0_2000['count_3_star'] = count_3_star\n",
    "# star_ratings_0_2000['count_2_star'] = count_2_star\n",
    "# star_ratings_0_2000['count_1_star'] = count_1_star\n",
    "\n",
    "# star_ratings_0_2000.to_csv('star_ratings_0_2000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# star_ratings_18_19 = pd.concat([star_ratings_18_19, category_ratings_18_19], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# star_ratings_18_19.to_csv('all_ratings_18_19', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count_5_star</th>\n",
       "      <th>count_4_star</th>\n",
       "      <th>count_3_star</th>\n",
       "      <th>count_2_star</th>\n",
       "      <th>count_1_star</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>company_rating</th>\n",
       "      <th>work_life_balance</th>\n",
       "      <th>pay_and_benefits</th>\n",
       "      <th>job_security_and_advancement</th>\n",
       "      <th>management</th>\n",
       "      <th>culture</th>\n",
       "      <th>EmployerName</th>\n",
       "      <th>CompanyNumber</th>\n",
       "      <th>employer_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"RED BAND\" CHEMICAL COMPANY, LIMITED</td>\n",
       "      <td>SC016876</td>\n",
       "      <td>\"RED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6 reviews</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>118 LIMITED</td>\n",
       "      <td>03951948</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123 EMPLOYEES LTD</td>\n",
       "      <td>10530651</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1509 GROUP</td>\n",
       "      <td>04104101</td>\n",
       "      <td>1509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4 reviews</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1610 LIMITED</td>\n",
       "      <td>06727055</td>\n",
       "      <td>1610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  count_5_star count_4_star count_3_star count_2_star count_1_star  \\\n",
       "0          NaN          NaN          NaN          NaN          NaN   \n",
       "1            1            3            2            0            0   \n",
       "2          NaN          NaN            2            0            0   \n",
       "3          NaN          NaN            2            0            0   \n",
       "4            2            1            0            1            0   \n",
       "\n",
       "  number_of_reviews  company_rating work_life_balance pay_and_benefits  \\\n",
       "0               NaN             NaN               NaN              NaN   \n",
       "1         6 reviews             3.8               3.3              2.5   \n",
       "2               NaN             NaN               NaN              NaN   \n",
       "3               NaN             NaN               NaN              NaN   \n",
       "4         4 reviews             4.0               4.0              3.8   \n",
       "\n",
       "  job_security_and_advancement management culture  \\\n",
       "0                          NaN        NaN     NaN   \n",
       "1                          2.5        3.0     3.3   \n",
       "2                          NaN        NaN     NaN   \n",
       "3                          NaN        NaN     NaN   \n",
       "4                          3.5        3.0     3.5   \n",
       "\n",
       "                           EmployerName CompanyNumber employer_clean  \n",
       "0  \"RED BAND\" CHEMICAL COMPANY, LIMITED      SC016876           \"RED  \n",
       "1                           118 LIMITED      03951948            118  \n",
       "2                     123 EMPLOYEES LTD      10530651            123  \n",
       "3                            1509 GROUP      04104101           1509  \n",
       "4                          1610 LIMITED      06727055           1610  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ratings_18_19 = pd.read_csv('all_ratings_18_19.csv')\n",
    "all_ratings_18_19.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Scrape the review data (pros, cons, main text and header). To do this, I had to do two things, before saving to a dataframe:\n",
    " ### a) Identify the number of pages to loop through for each company - there was a number at the top stating the total number of reviews and I knew each page displays 20 results and I didn't want any repeats as it would have been quite difficult to get rid of duplicates, since all reviews would be included in the same row of the dataframe as one list. I wrote a formula that used the total number of reviews to determine how many pages to loop through.\n",
    "### b) Scrape the date of review, convert to a datetime series and ensure that the date of the review is not after gender pay gap data period. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/requests/packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 2.7, use buffering of HTTP responses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 2.6 and older\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: getresponse() got an unexpected keyword argument 'buffering'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-2e0f4ce2d047>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0murl_template_company\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://uk.indeed.com/cmp/{}/reviews?fcountry=GB\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mr_company\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_template_company\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompany\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0msoup_company\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr_company\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'html.parser'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup_company\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'div'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"cmp-ReviewsCount\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0;31m# By explicitly closing the session, we avoid leaving sockets open which\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;31m# can trigger a ResourceWarning in some cases, and look like a memory leak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    466\u001b[0m         }\n\u001b[1;32m    467\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;31m# Resolve redirects if allowed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_redirects\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# Shuffle things around if there's history.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;31m# Resolve redirects if allowed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_redirects\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# Shuffle things around if there's history.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mresolve_redirects\u001b[0;34m(self, resp, req, stream, timeout, verify, cert, proxies, **adapter_kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepared_request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             resp = self.send(\n\u001b[0m\u001b[1;32m    188\u001b[0m                 \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m                 \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m                 resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    361\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/requests/packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, **response_kw)\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0;31m# Make the request on the httplib connection object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m             httplib_response = self._make_request(conn, method, url,\n\u001b[0m\u001b[1;32m    558\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m                                                   body=body, headers=headers)\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/requests/packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    376\u001b[0m                 \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 2.6 and older\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m                 \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1345\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1347\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1348\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1239\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1241\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# scraping the review data: after applying the datetime filter\n",
    "url_template = \"https://uk.indeed.com/cmp/{}/reviews?fcountry=GB&start={}\"\n",
    "review_date = []\n",
    "review_header = []\n",
    "review_text = []\n",
    "review_pros = []\n",
    "review_cons = []\n",
    "march_31_2019 = datetime(2019, 3, 31).toordinal()\n",
    "\n",
    "for company in indeed_comp.employer_clean[0:2105]:\n",
    "    company_date = []\n",
    "    company_header = []\n",
    "    company_text = []\n",
    "    company_pros = []\n",
    "    company_cons = []\n",
    "\n",
    "    url_template_company = \"https://uk.indeed.com/cmp/{}/reviews?fcountry=GB\"\n",
    "    r_company = requests.get(url_template_company.format(company))\n",
    "    soup_company = BeautifulSoup(r_company.text, 'html.parser')\n",
    "    counts = soup_company.find('div', attrs={'class':\"cmp-ReviewsCount\"})\n",
    "    try:\n",
    "        number_reviews = int((counts.findChild('b').text.strip()))\n",
    "    except:\n",
    "        number_reviews = 20\n",
    "    max_reviews = ((math.ceil(number_reviews/20)))*20\n",
    "    for page in range(0,max_reviews,20):\n",
    "        time.sleep(random.randint(1, 4))\n",
    "        r = requests.get(url_template.format(company, page))\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "        for review in soup.find_all('div', attrs={'class':\"cmp-Review\", 'itemprop':'review'}):\n",
    "            try:\n",
    "                review_author = review.find('span', attrs={'class':\"cmp-ReviewAuthor\"}).text.strip()\n",
    "                date = re.findall(r'(\\w+\\s\\w+\\s\\w+)$', review_author)\n",
    "                for i in date:\n",
    "                    datetime_object = datetime.strptime(i, '%d %B %Y')\n",
    "                \n",
    "                if datetime_object.toordinal() < march_31_2019:\n",
    "                    company_date.append(date)\n",
    "                else:\n",
    "                    pass\n",
    "                \n",
    "            except:\n",
    "                pass\n",
    "                \n",
    "            if datetime_object.toordinal() < march_31_2019:\n",
    "                try:\n",
    "                    company_header.append(review.find('a', attrs={'class':\"cmp-Review-titleLink\"}).text.strip())\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                text_section = review.find('div', attrs={'class':\"cmp-Review-text\"})\n",
    "                try:\n",
    "                    company_text.append(text_section.findChild('span', attrs={'class':\"cmp-NewLineToBr-text\"}).text.strip())\n",
    "                except:\n",
    "                    pass\n",
    "                pros_section = review.find('div', attrs={'class':\"cmp-ReviewProsCons-prosText\"})\n",
    "                try: \n",
    "                    company_pros.append(pros_section.find('span', attrs={'class':\"cmp-NewLineToBr-text\"}).text.strip())\n",
    "                except:\n",
    "                    pass\n",
    "                cons_section = review.find('div', attrs={'class':\"cmp-ReviewProsCons-consText\"})\n",
    "                try: \n",
    "                    company_cons.append(cons_section.find('span', attrs={'class':\"cmp-NewLineToBr-text\"}).text.strip())\n",
    "                except:\n",
    "                    pass\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    review_date.append(company_date)\n",
    "    review_header.append(company_header)\n",
    "    review_text.append(company_text)\n",
    "    review_pros.append(company_pros)\n",
    "    review_cons.append(company_cons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review_details_0_500 = pd.DataFrame()\n",
    "\n",
    "# review_details_0_500['review_date'] = review_date\n",
    "# review_details_0_500['review_header'] = review_header\n",
    "# review_details_0_500['review_text'] = review_text\n",
    "# review_details_0_500['review_pros'] = review_pros\n",
    "# review_details_0_500['review_cons'] = review_cons\n",
    "\n",
    "# review_details_0_500.to_csv('review_details_0_500')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_reviews_18_19 = pd.concat([review_details_18_19, all_ratings_18_19], axis=1)\n",
    "# all_reviews_18_19.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_reviews_18_19.to_csv('all_reviews_18_19', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

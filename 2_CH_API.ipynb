{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Companies House API\n",
    "\n",
    "* Tricky to get the key to work, but eventually managed to figure out how to get what I needed from companies house."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPG_18_19 = pd.read_csv('/Users/gitas/Desktop/GA/Capstone/Gender_Pay_Gap_Data/UK_Gender_Pay_Gap_Data_2018_2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPG_18_19.dropna(subset=['CompanyNumber', 'DiffMeanBonusPercent', 'DiffMedianBonusPercent'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPG_18_19.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8105 entries, 0 to 8104\n",
      "Data columns (total 25 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   EmployerName               8105 non-null   object \n",
      " 1   Address                    8105 non-null   object \n",
      " 2   CompanyNumber              8105 non-null   object \n",
      " 3   SicCodes                   7713 non-null   object \n",
      " 4   DiffMeanHourlyPercent      8105 non-null   float64\n",
      " 5   DiffMedianHourlyPercent    8105 non-null   float64\n",
      " 6   DiffMeanBonusPercent       8105 non-null   float64\n",
      " 7   DiffMedianBonusPercent     8105 non-null   float64\n",
      " 8   MaleBonusPercent           8105 non-null   float64\n",
      " 9   FemaleBonusPercent         8105 non-null   float64\n",
      " 10  MaleLowerQuartile          8105 non-null   float64\n",
      " 11  FemaleLowerQuartile        8105 non-null   float64\n",
      " 12  MaleLowerMiddleQuartile    8105 non-null   float64\n",
      " 13  FemaleLowerMiddleQuartile  8105 non-null   float64\n",
      " 14  MaleUpperMiddleQuartile    8105 non-null   float64\n",
      " 15  FemaleUpperMiddleQuartile  8105 non-null   float64\n",
      " 16  MaleTopQuartile            8105 non-null   float64\n",
      " 17  FemaleTopQuartile          8105 non-null   float64\n",
      " 18  CompanyLinkToGPGInfo       5669 non-null   object \n",
      " 19  ResponsiblePerson          7840 non-null   object \n",
      " 20  EmployerSize               8105 non-null   object \n",
      " 21  CurrentName                8105 non-null   object \n",
      " 22  SubmittedAfterTheDeadline  8105 non-null   bool   \n",
      " 23  DueDate                    8105 non-null   object \n",
      " 24  DateSubmitted              8105 non-null   object \n",
      "dtypes: bool(1), float64(14), object(10)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "GPG_18_19.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "\n",
    "#### Note - for all the below scrapes, since I was limited to 600 requests per 5 minutes, I did these for 600 companies then set a timer for 6 minutes before running for the next 600 etc, each time appending to the dictionary. Once data for all companies were scraped, I converted the dictionary to a dataframe and saved to a csv file. \n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Company Overview\n",
    "\n",
    "#### Utilising the API to obtain basic company information such as the company number, status, creation date, jurisdiction, address and type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies_house = {'company_no' : [],\n",
    "                    'company_status' : [],\n",
    "                    'creation_date' : [],\n",
    "                    'jurisdiction' : [],\n",
    "                    'registered_address_country' : [],\n",
    "                    'company_type' : []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pprint import pprint\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import base64\n",
    "import requests\n",
    "apiKey = 'F11LgkEtJd6NvuWGCs7n88nlbaXp3cC5JjJ85sP6:'\n",
    "list_companies_dict = []\n",
    "    \n",
    "for company_number in GPG_18_19['CompanyNumber'][0:2000]:\n",
    "    url1 = 'https://api.companieshouse.gov.uk/company/' + company_number\n",
    "    re = requests.get(url1,auth=HTTPBasicAuth(apiKey,'')).json()\n",
    "    list_companies_dict.append(re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in list_companies_dict:\n",
    "    try:\n",
    "        companies_house['company_no'].append(item['company_number'])\n",
    "    except:\n",
    "        companies_house['company_no'].append('None')\n",
    "\n",
    "    try:\n",
    "        companies_house['company_status'].append(item['company_status'])\n",
    "    except:\n",
    "        companies_house['company_status'].append('None')\n",
    "\n",
    "\n",
    "    try:\n",
    "        companies_house['creation_date'].append(item['date_of_creation'])\n",
    "    except:\n",
    "        companies_house['creation_date'].append('None')\n",
    "\n",
    "    try:\n",
    "        companies_house['jurisdiction'].append(item['jurisdiction'])\n",
    "    except:\n",
    "        companies_house['jurisdiction'].append('None')\n",
    "\n",
    "    try:\n",
    "        companies_house['registered_address_country'].append(item['registered_office_address']['country'])\n",
    "    except:\n",
    "        companies_house['registered_address_country'].append('None')\n",
    "\n",
    "    try:\n",
    "        companies_house['company_type'].append(item['type'])\n",
    "    except:\n",
    "        companies_house['company_type'].append('None')\n",
    "\n",
    "# companies_house = pd.DataFrame(companies_house, index = companies_house['company_no'])\n",
    "# companies_house.to_csv('companies_house_18_19')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Officers\n",
    "\n",
    "#### Utilising the API to obtain a list of all company officers, this was then used to calculate the % female officers for each company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "officers = {'company_no' : [],\n",
    "            'name' : [],\n",
    "            'date_appointed' : [],\n",
    "            'date_resigned' : []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_companies_dict = []\n",
    "\n",
    "for company_number in GPG_18_19['CompanyNumber'][0:2000]:\n",
    "    url2 = 'https://api.companieshouse.gov.uk/company/' + company_number + '/officers'\n",
    "    re = requests.get(url2,auth=HTTPBasicAuth(apiKey,'')).json()\n",
    "    list_companies_dict.append(re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "for comp in list_companies_dict:\n",
    "    try:\n",
    "        for item in comp['items']:\n",
    "            try:\n",
    "                officers['company_no'].append(item['links']['self'][9:17])\n",
    "            except:\n",
    "                officers['company_no'].append('None')\n",
    "\n",
    "            try:\n",
    "                officers['name'].append(item['name'])\n",
    "            except:\n",
    "                officers['name'].append('None')\n",
    "\n",
    "            try:\n",
    "                officers['date_appointed'].append(item['appointed_on'])\n",
    "            except:\n",
    "                officers['date_appointed'].append('None')\n",
    "\n",
    "            try:\n",
    "                officers['date_resigned'].append(item['resigned_on'])\n",
    "            except:\n",
    "                officers['date_resigned'].append('None')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# officers = pd.DataFrame(officers, index = officers['company_no'])\n",
    "# officers.to_csv('officers_18_19_v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Company Location\n",
    "\n",
    "#### Utilising the API to obtain information about the company location - whilst this was also included in the original government gender pay gap dataset, this information needed to be cleaned and was in a single string. I therefore decided to scrape this information from companies house - only using the sections of the address I was interested in (locality and country) rather than the full address. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_location = {'company_no' : [],\n",
    "                    'locality' : [],\n",
    "                    'country' : []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "apiKey = 'F11LgkEtJd6NvuWGCs7n88nlbaXp3cC5JjJ85sP6:'\n",
    "list_companies_dict = []\n",
    "    \n",
    "for company_number in GPG_18_19['CompanyNumber'][0:2000]:\n",
    "    url1 = 'https://api.companieshouse.gov.uk/company/' + company_number\n",
    "    re = requests.get(url1,auth=HTTPBasicAuth(apiKey,'')).json()\n",
    "    list_companies_dict.append(re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in list_companies_dict:\n",
    "    try:\n",
    "        company_location['company_no'].append(item['company_number'])\n",
    "    except:\n",
    "        company_location['company_no'].append('None')\n",
    "\n",
    "    try:\n",
    "        company_location['locality'].append(item['registered_office_address']['locality'])\n",
    "    except:\n",
    "        company_location['locality'].append('None')\n",
    "    \n",
    "    try:\n",
    "        company_location['country'].append(item['registered_office_address']['country'])\n",
    "    except:\n",
    "        company_location['country'].append('None')\n",
    "        \n",
    "# company_location = pd.DataFrame(company_location, index = company_location['company_no'])        \n",
    "# company_location.to_csv('company_location_18_19')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
